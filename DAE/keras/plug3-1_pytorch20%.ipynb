{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcdf1bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/daniel_flower/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "# Load and process the data\n",
    "aggregate_df1 = pd.read_csv('/home/awinlab/Documents/kevin/elec220.csv', index_col='datetime', parse_dates=True)\n",
    "aggregate_df1 = aggregate_df1[:900000]\n",
    "\n",
    "plug1_1 = pd.read_csv('/home/awinlab/Documents/kevin/plug3-1.csv', index_col='datetime', parse_dates=True)\n",
    "plug1_1 = plug1_1[:900000]\n",
    "\n",
    "aggregate_df1 = aggregate_df1.drop(['Unnamed: 0','id','device', 'vo', 'cu', 'reactive', 'apparent', 'pf', 'freq'], axis=1)\n",
    "plug1_1 = plug1_1.drop(['Unnamed: 0','id','device', 'vo', 'cu', 'reactive', 'apparent', 'pf', 'freq'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8acce1",
   "metadata": {},
   "source": [
    " torch.nn.utils.rnn.pack_sequence 來保留每個時間序列之間的關係，並使用 torch.nn.utils.rnn.pad_sequence 來將所有序列的長度調整為最長序列的長度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1e610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, length=100):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx: idx + self.length]\n",
    "        y = self.y[idx: idx + self.length]\n",
    "        return X, y\n",
    "\n",
    "training_size = int(len(aggregate_df1) * 0.2)\n",
    "X_train = aggregate_df1[:training_size]\n",
    "X_test = aggregate_df1[training_size:]\n",
    "\n",
    "y_train = plug1_1[:training_size]\n",
    "y_test = plug1_1[training_size:]\n",
    "\n",
    "X_train = torch.tensor(X_train.values).float()\n",
    "X_test = torch.tensor(X_test.values).float()\n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "y_test = torch.tensor(y_test.values).float()\n",
    "\n",
    "batch_size=60\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train, length=100)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, \n",
    "                                           collate_fn=lambda x: (torch.nn.utils.rnn.pad_sequence([i[0] for i in x], batch_first=True),\n",
    "                                                                 torch.nn.utils.rnn.pad_sequence([i[1] for i in x], batch_first=True)))\n",
    "\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test, length=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                                           collate_fn=lambda x: (torch.nn.utils.rnn.pad_sequence([i[0] for i in x], batch_first=True),\n",
    "                                                                 torch.nn.utils.rnn.pad_sequence([i[1] for i in x], batch_first=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d38b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, length=100):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx: idx + self.length]\n",
    "        y = self.y[idx: idx + self.length]\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bccee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=60\n",
    "\n",
    "# train_dataset = TimeSeriesDataset(X_train, y_train, length=100)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# test_dataset = TimeSeriesDataset(X_test, y_test, length=100)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d46c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_timeseries(dataset, look_back=100):\n",
    "#     dataX = []\n",
    "#     for i in range(len(dataset) - look_back):\n",
    "#         a = dataset[i:(i + look_back)]\n",
    "#         dataX.append(a.values)\n",
    "#     return np.array(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf87e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = create_timeseries(aggregate_df1)\n",
    "# y_train = create_timeseries(plug1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d371138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180000, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9afa4f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180000, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d4df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = data_X_train.reshape(-1, 1, 100)\n",
    "# train_y = data_y_train.reshape(-1, 1, 1)\n",
    "# test_X = data_X_test.reshape(-1, 1, 100)\n",
    "\n",
    "# train_X = torch.from_numpy(train_X)\n",
    "# train_y = torch.from_numpy(train_y)\n",
    "# test_X = torch.from_numpy(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1695867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_X = data_X.reshape(data_X.shape[0], data_X.shape[1], 1)\n",
    "# data_y = data_y.reshape(data_y.shape[0], data_y.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d37e6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_size = int(len(aggregate_df1) * 0.8)\n",
    "# data_X_train = data_X[training_size:]\n",
    "# data_X_test = data_X[:training_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2477eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class ConvolutionalModel(nn.Module):\n",
    "    def __init__(self, input_shape, n_input):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=100, out_channels=8, kernel_size=4, padding=2, stride=1, bias=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fc0 = nn.Linear(16,(n_input-0)*8)\n",
    "        self.fc1 = nn.Linear((n_input-0)*8, 128)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=(n_input-0)* 8)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(in_features=(n_input-0) * 8, out_features=128)\n",
    "        self.dropout4 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = nn.Conv1d(8, 1, kernel_size=4, padding=2, stride=1)\n",
    "\n",
    "        self.fc4 = nn.Linear(17, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = x.view(x.size(0), 8, -1)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "n_input = 100\n",
    "input_shape = (n_input, 1)\n",
    "model = ConvolutionalModel(input_shape, n_input)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5aac786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/daniel_flower/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([6000, 1])) that is different to the input size (torch.Size([60])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/awinlab/anaconda3/envs/daniel_flower/lib/python3.7/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([6000, 1])) that is different to the input size (torch.Size([60])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/awinlab/anaconda3/envs/daniel_flower/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([2000, 1])) that is different to the input size (torch.Size([20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/awinlab/anaconda3/envs/daniel_flower/lib/python3.7/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([2000, 1])) that is different to the input size (torch.Size([20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.4896725992439315e-05, MAE: 0.005375513341277838\n",
      "Epoch 2, Loss: 5.5679713284462196e-08, MAE: 0.00019092709408141673\n",
      "Epoch 3, Loss: 6.253664946997972e-11, MAE: 4.6148898036335595e-06\n",
      "Epoch 4, Loss: 9.071458167975166e-11, MAE: 9.50247067521559e-06\n",
      "Epoch 5, Loss: 1.8773134435878802e-10, MAE: 1.368597168038832e-05\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import L1Loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mae_fn = L1Loss()\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.reshape(-1, 100, 1)\n",
    "#         model.zero_grad()\n",
    "        y_pred = model(X_batch) \n",
    "        loss = loss_fn(y_pred.view(-1), y_batch.view(-1,1))\n",
    "#         optimizer.zero_grad()\n",
    "        mae = mae_fn(y_pred.view(-1), y_batch.view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, MAE: {mae.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8020009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predict.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5265e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = np.concatenate([p.detach().numpy() for p in predict], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3760dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = plug1_1\n",
    "y_val = plug1_1[training_size:]\n",
    "y_val = y_val.values.reshape(y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eabe5c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_val)\n",
    "plt.plot(predict_list,color='darkorange')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(\"W\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel_flower",
   "language": "python",
   "name": "daniel_flower"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
